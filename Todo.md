# LLM 驱动的心理健康咨询与沟通辅导平台 (v2.1)

## 1. 项目愿景与概述

本项目旨在构建一个创新的大型语言模型（LLM）驱动的应用，该应用具备两大核心功能：
1.  为用户提供初步的、富有同理心的心理健康咨询服务。
2.  为在对话中难以组织语言、不知如何回应的用户提供实时的沟通辅导。

平台致力于通过整合先进的 LLM 技术、检索增强生成 (RAG) 以及严格的伦理框架，提升用户的心理福祉和沟通效能。我们强调模块化设计，以实现独立开发、灵活扩展和针对性优化。

## 2. 核心功能与模块

### 2.1. 心理健康咨询模块
* **目标：** 提供易于获取的初步心理支持，作为用户自我探索和寻求专业帮助的桥梁。**非替代专业人类治疗师。**
* **主要能力：**
    * 共情对话与积极倾听
    * 心理健康知识普及 (通过 RAG 实现)
    * 基础认知行为疗法 (CBT) 技术引导 (例如，思维挑战)
    * 痛苦识别与危机分流 (引导至人工服务)

### 2.2. 沟通回应辅导模块
* **目标：** 帮助用户在各种社交或职业场景下，尤其是在感到不确定或面对困难对话时，有效组织语言。
* **主要能力：**
    * 对话情境分析与理解
    * “不知如何回应”辅助：生成多种回应选项并解释其潜在影响
    * 社交技能与沟通礼仪指导 (通过 RAG 实现)
    * 换位思考与困难对话演练
    * 培养用户的沟通“元认知循环”

## 3. 关键差异化特性

* **双重整合：** 将心理健康支持与沟通技巧辅导独特地结合在单一平台。
* **实用导向：** 专注于可操作的沟通策略和心理应对技巧。
* **伦理核心：** 内建动态的伦理与安全框架，适应不同模块和用户状态的需求。
* **知识驱动：** 利用 RAG 为两个模块提供准确、相关的背景知识。
* **灵活模型支持：** 支持多种商业和开源 LLM，包括通过 API 调用的模型和本地部署的微调模型。

## 4. 技术栈选型与理由

* **核心 LLM 框架：** **Langchain**
    * *理由：* 强大的 LLM 应用构建和编排能力，支持链式调用、智能体、RAG、记忆模块，极大简化复杂工作流开发。
* **用户界面：** **Streamlit**
    * *理由：* 快速原型开发，易于构建交互式 Web 应用，适合数据科学家和 AI 工程师快速迭代。
* **后端服务 (推荐)：** **Python (FastAPI)**
    * *理由：* Python 在 AI/ML 领域的统治地位，拥有丰富的库支持 (HuggingFace Transformers, PyTorch 等)。FastAPI 提供高性能、易于学习的异步 API 开发。
* **LLM 模型：**
    * **API 调用模型：**
        * OpenAI (GPT 系列)
        * Google Gemini
        * DeepSeek API
        * 硅基流动 (SiliconFlow) API
        * 书生·浦语 (InternLM) API
        * 讯飞星火 (iFlyTek Spark) API
    * **本地部署模型：**
        * 通过 **Ollama** 调用本地运行的开源模型，特别是经过微调以适应特定任务需求的模型 (例如，基于 EmoLLM 理念微调的模型)。
    * *理由：* 提供模型选择的灵活性，平衡性能、成本和特定任务的适用性。允许利用最新的商业模型能力，同时也支持使用定制化的本地模型以保护数据隐私或降低延迟。
    * *微调策略：* 采用 LoRA/QLoRA 等技术进行高效微调，考虑 DPO 进行偏好对齐。
* **LLM 调用与 API Key 管理：**
    * 所有外部 LLM 服务的 API Key 将通过环境变量进行管理 (例如，存储在 `.env` 文件中，由应用在启动时加载)。
    * Langchain 将用于统一不同 LLM 接口的调用方式。
* **向量数据库 (RAG)：** **ChromaDB / FAISS (本地), Pinecone / Weaviate (云端)**
    * *理由：* 实现高效的语义相似性搜索，是 RAG 模块的核心。
* **数据库 (结构化/非结构化)：** **PostgreSQL (用户数据), MongoDB (对话日志)**
    * *理由：* PostgreSQL 保证数据一致性；MongoDB 灵活存储对话等非结构化数据。
* **容器化与部署：** **Docker, Kubernetes (K8s)**
    * *理由：* 实现标准化部署、扩展和管理。考虑 Ollama / LMDeploy 进行本地/私有化模型部署。

## 5. 数据处理与知识整合

1.  **用户输入：** 通过 Streamlit 界面接收。
2.  **意图识别与路由：** 后端服务判断用户意图，分发至相应模块 (心理健康/沟通辅导)。
3.  **LLM 处理：**
    * **直接生成：** 对于通用对话或创造性任务。
    * **RAG 增强：** 用户查询首先通过向量数据库检索相关知识片段，然后与原始查询一同送入 LLM 生成更准确、更具上下文的回应。
        * 心理健康知识库：包含心理教育材料、CBT 原则、危机干预信息等。
        * 沟通辅导知识库：包含社交规范、沟通技巧、特定场景回应策略等。
4.  **个性化 (需用户明确同意)：** 基于用户历史互动（匿名化处理）调整回应风格或建议。
5.  **对话历史管理：** 维护会话状态以支持多轮连贯对话。

## 6. 伦理、隐私与安全框架

* **知情同意：** 对数据收集、使用 (包括模型微调和个性化) 和存储进行清晰、细致的告知。
* **数据最小化与匿名化：** 仅收集必要数据，并在可能的情况下进行匿名化/去标识化处理。
* **安全措施：** 端到端加密、访问控制、定期安全审计。API Key 等敏感信息严格保密。
* **偏见检测与缓解：** 使用多样化数据集，定期审计模型输出，整合文化敏感性。
* **危机管理：** 强大的危机识别机制，并强制升级至人工干预路径。
* **动态伦理协议：** 系统需能根据用户所处模块和当前对话内容，动态调整其回应策略和风险阈值，例如，在沟通模块检测到危机信号时，应切换至危机干预流程。
* **透明度：** 清晰说明 AI 能力边界，提供隐私政策访问。

## 7. 项目阶段规划 (高级别)

1.  **阶段一：MVP - 核心功能验证**
    * 心理健康模块：基础共情对话 (可配置选用任一支持的 LLM)，基础 RAG (少量核心知识)。
    * 沟通辅导模块：核心“不知如何回应”辅助 (多选项生成)，基础 RAG。
    * Streamlit 基础 UI，手动模块切换。
    * 核心危机检测与提示。
2.  **阶段二：功能增强与整合**
    * 扩展知识库，优化 RAG 性能。
    * 引入基础 CBT 练习和困难对话演练。
    * 初步个性化功能 (需同意)。
    * 完善 UI/UX，优化模块切换体验。
    * 建立初步的“人在环”评估流程。
3.  **阶段三：深度优化与扩展**
    * 基于用户反馈和收集数据进行模型微调 (LoRA/QLoRA, DPO)，优先部署于本地 Ollama。
    * 实现更高级的个性化和主动支持功能 (伦理约束下)。
    * 探索多模态交互。
    * 完善动态伦理协议的实现。
    * 建立成熟的评估与迭代体系。

## 8. 快速开始 (示例)

```bash
# 1. 克隆仓库
git clone [your-repo-url]
cd [your-repo-name]

# 2. 创建并激活虚拟环境
python -m venv venv
source venv/bin/activate # Linux/macOS
# venv\Scripts\activate # Windows

# 3. 安装依赖
pip install -r requirements.txt

# 4. 配置环境变量 (例如 API 密钥, 数据库连接字符串)
cp .env.example .env
# 编辑 .env 文件，填入必要的 API Keys:
# OPENAI_API_KEY="sk-..."
# GEMINI_API_KEY="..."
# DEEPSEEK_API_KEY="..."
# SILICONFLOW_API_KEY="..."
# INTERNLM_API_KEY="..." # 或其他认证方式
# IFLYTEK_SPARK_APPID="..."
# IFLYTEK_SPARK_API_SECRET="..."
# IFLYTEK_SPARK_API_KEY="..."
# OLLAMA_BASE_URL="http://localhost:11434" # 如果使用本地 Ollama
# ... 其他配置

# 5. 初始化向量数据库 (如果使用本地 RAG)
# python scripts/initialize_vector_db.py

# 6. 运行 Streamlit 应用
streamlit run app.py
